{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4dfba0",
   "metadata": {},
   "source": [
    "# Basic Prompt Structure with Ollama\n",
    "\n",
    "This notebook demonstrates how to structure prompts for Ollama models using the Python API.\n",
    "\n",
    "You will learn how to:\n",
    "- Send basic prompts to the model\n",
    "- Experiment with prompt engineering\n",
    "- Adjust system prompts and temperature for creative control\n",
    "\n",
    "Run each cell in order. Make sure your Ollama server is running locally.\n",
    "\n",
    "**Note:** Multi-turn conversation examples are now at the end of the notebook for better flow. Redundant exercises have been removed for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run previous notebook to setup the basic environment\n",
    "def pretty_print_response():\n",
    "    return\n",
    "def get_completion():\n",
    "    return\n",
    "%run ../tutorial/00_Tutorial_How-To.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1fb4a",
   "metadata": {},
   "source": [
    "## Basic Prompt Example\n",
    "\n",
    "Let's send a simple prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Prompt Example using get_completion\n",
    "prompt = \"What is the capital of France?\"\n",
    "pretty_print_response(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849fe6f",
   "metadata": {},
   "source": [
    "## Try Your Own Prompt\n",
    "\n",
    "Edit the cell below to experiment with your own prompt structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own prompt\n",
    "prompt = '[Type your prompt here]'\n",
    "pretty_print_response(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cc8d6",
   "metadata": {},
   "source": [
    "## System Prompt and Temperature Example\n",
    "\n",
    "You can use the system prompt to control the model's behavior and adjust the temperature for more creative or deterministic responses.\n",
    "\n",
    "**Temperature controls creativity/randomness:**\n",
    "- Low values (0.0–0.3): more predictable, focused answers\n",
    "- High values (0.7–1.0): more creative, varied responses\n",
    "\n",
    "Try changing the temperature in the examples below to see how the output changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb487807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use system prompt to make the model answer as a pirate\n",
    "prompt = \"What is the capital of France?\"\n",
    "system_prompt = \"You are a pirate. Always answer in pirate speak.\"\n",
    "pretty_print_response(get_completion(prompt, system_prompt=system_prompt, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use system prompt to make the model answer as a Shakespearean character\n",
    "prompt = \"What is the capital of France?\"\n",
    "system_prompt = \"You are William Shakespeare. Answer as if you are writing a play.\"\n",
    "pretty_print_response(get_completion(prompt, system_prompt=system_prompt, temperature=0.3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
