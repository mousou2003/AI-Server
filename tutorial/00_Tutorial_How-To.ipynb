{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65c02ea",
   "metadata": {},
   "source": [
    "# Ollama Environment Setup\n",
    "\n",
    "This cell sets up the Python environment and connects to your local Ollama server.\n",
    "It installs required packages, sets model and host variables, and prepares the Ollama client for use.\n",
    "\n",
    "**Purpose:**\n",
    "- Ensures all dependencies are installed and variables are set.\n",
    "- Initializes the Ollama client so you can send prompts to the model.\n",
    "- Used as a setup step in other tutorial notebooks via `%run 00_Tutorial_How-To.ipynb`.\n",
    "- Run this cell first before using any prompt engineering or model interaction cells.\n",
    "\n",
    "Refer to the project [README](../readme.md) for instructions on installing the local Ollama server.\n",
    "\n",
    "---\n",
    "\n",
    "## Usage Notes & Tips ðŸ’¡\n",
    "- This tutorial uses Qwen 2.5 7B Instruct with temperature 0. You can change the model name to any available in the [Ollama model library](https://ollama.com/search).\n",
    "- Use `Shift + Enter` to execute the cell and move to the next one.\n",
    "\n",
    "### The Ollama Python Library\n",
    "We will be using the [Ollama Python Library](https://github.com/ollama/ollama-python) throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebabdc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'client' not in globals():\n",
    "    # Install required dependencies\n",
    "    %pip install -U ollama tqdm pickleshare nbformat --quiet\n",
    "    %pip install python-dotenv --quiet\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    # Connect to Ollama Service\n",
    "    from ollama import Client, ChatResponse, Options\n",
    "    from IPython.display import display, Markdown\n",
    "\n",
    "    load_dotenv()  # This loads variables from .env into the environment\n",
    "    output = []\n",
    "\n",
    "    # Now you can use OLLAMA_HOST from the .env file\n",
    "    OLLAMA_HOST = os.getenv('OLLAMA_HOST')\n",
    "    client = Client(host=OLLAMA_HOST)\n",
    "    output.append(f'**Connected to Ollama at:** {OLLAMA_HOST}')\n",
    "    # Set up your model name from .env or use default\n",
    "    MODEL_NAME = os.getenv('MODEL_NAME', 'qwen2.5:14b-instruct')\n",
    "    output.append(f'**Using model:** {MODEL_NAME}')\n",
    "    display(Markdown(\"\\n\".join(output)))\n",
    "else:\n",
    "    from IPython.display import display, Markdown\n",
    "    output = []\n",
    "    output.append(f'**Using Ollama host:** {client._client.base_url}')\n",
    "    output.append(\"**Ollama client already initialized.**\")\n",
    "    display(Markdown(\"\\n\".join(output)))\n",
    "\n",
    "# Helper function to send a prompt or conversation to Ollama and get the response\n",
    "def get_completion(prompt_or_messages, system_prompt=\"\", max_tokens=200, temperature=0.0):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    if isinstance(prompt_or_messages, str):\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt_or_messages})\n",
    "    elif isinstance(prompt_or_messages, list):\n",
    "        messages = prompt_or_messages\n",
    "    else:\n",
    "        raise ValueError(\"prompt_or_messages must be a string or a list of dicts\")\n",
    "\n",
    "    # ðŸ”Ž DEBUG: display what we send\n",
    "    from IPython.display import display, Markdown\n",
    "    debug_str = f\"\\n=== Sending to Ollama ===\\n{messages}\\n=========================\\n\"\n",
    "    display(Markdown(f\"```\\n{debug_str}\\n```\"))\n",
    "\n",
    "    response: ChatResponse = client.chat(\n",
    "        model=MODEL_NAME,\n",
    "        options=Options(max_tokens=max_tokens, temperature=temperature),\n",
    "        messages=messages\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def pretty_print_response(response: ChatResponse):\n",
    "    from datetime import datetime  # For friendly timestamp formatting\n",
    "    def ns_to_sec(ns):  # Convert nanoseconds to seconds for readability\n",
    "        return f\"{ns/1e9:.2f} s\" if ns is not None else None\n",
    "    output = []\n",
    "    output.append(f\"**Model:** {response.model}\")\n",
    "    # Timestamp\n",
    "    if response.created_at:\n",
    "        try:\n",
    "            dt = datetime.fromisoformat(response.created_at.replace('Z', '+00:00'))\n",
    "            output.append(f\"**Created at:** {dt.strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "        except Exception:\n",
    "            output.append(f\"**Created at:** {response.created_at}\")\n",
    "    else:\n",
    "        output.append(f\"**Created at:** {response.created_at}\")\n",
    "    output.append(f\"**Done:** {response.done}\")\n",
    "    output.append(f\"**Done reason:** {response.done_reason}\")\n",
    "    output.append(f\"**Total duration:** {ns_to_sec(response.total_duration)}\")\n",
    "    output.append(f\"**Load duration:** {ns_to_sec(response.load_duration)}\")\n",
    "    output.append(f\"**Prompt eval count:** {response.prompt_eval_count}\")\n",
    "    output.append(f\"**Prompt eval duration:** {ns_to_sec(response.prompt_eval_duration)}\")\n",
    "    output.append(f\"**Eval count:** {response.eval_count}\")\n",
    "    output.append(f\"**Eval duration:** {ns_to_sec(response.eval_duration)}\")\n",
    "    msg = response.message\n",
    "    if msg:\n",
    "        output.append(f\"**Message Role:** {msg.role}\")\n",
    "        output.append(f\"**Message Content:**\\n\\n{msg.content}\")\n",
    "    else:\n",
    "        output.append(\"**Full Response Object:**\\n\\n\" + str(response))\n",
    "    from IPython.display import display, Markdown\n",
    "    display(Markdown(\"\\n\".join(output)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
